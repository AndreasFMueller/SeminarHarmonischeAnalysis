%
% 2-casimir.tex
%
% (c) 2022 Prof Dr Andreas Müller, OST Ostschweizer Fachhochschule
%
\section{Casimir-Operator
\label{buch:operatoren:section:casimir}}
\kopfrechts{Casimir-Operator}
Warum spielt der Laplace-Operator so eine wichtige Rolle in den
Anwendungen?
Und gibt es für andere Definitionsgebiete einen Operator, der eine
ähnliche Rolle spielt?

%
% Invariante Differentialoperatoren
%
\subsection{Invariante Differentialoperatoren}
In diesem Abschnitt betrachten wir Differentialoperatoren auf
glatten Funktionen $f\in C^\infty(\mathbb{R}^n)$ auf $\mathbb{R}^n$.
Ein Differentialoperator $P$ der Ordnung $m$ kann geschrieben werden als
eine Summe
\[
Pf
=
\sum_{|\mathbf{l}|\le m}
a_{\bm{l}}(x)
D^{\bm{l}}
f.
\]
Der Operator kann natürlich auch als Pseudodifferentialoperator geschrieben
werden, er bekommt dann die Form
\begin{align*}
(Pf)(x)
&=
\int_{\mathbb{R}^n}
\frac{1}{(2\pi)^n}
\int_{\mathbb{R}^n}
e^{ik\cdot (x-y)}
\sum_{|\bm{l}|\le m}
a_{\bm{l}}(x)(ik)^{\bm{l}}
\,dk
\,dy
\end{align*}
mit dem Symbol
\[
a(x,k)
=
\sum_{|\bm{l}|\le m} a_{\bm{l}}(x) i^{|\bm{l}|} k^{\bm{l}}.
\]
Das Symbol eines Differentialoperators ist also ein Polynom in den
den Variablen $k_1,\dots,k_n$.

Der Raum $\mathbb{R}^n$ ist invariant unter sogenannten Bewegungen, also
beliebigen Verschiebungen und Drehungen.
Wir untersuchen jetzt, ob ein Differentialoperator wie $P$ unter solchen
Operationen ebenfalls invariant sein kann.
Damit ist folgendes gemeint.
Ist $\varphi\colon\mathbb{R}^n\to\mathbb{R}^n$ eine dieser Transformationen,
dann erzeugt die Zusammensetzung mit $\varphi$ eine lineare Abbildung
\[
T_\varphi
\colon
C^{\infty}(\mathbb{R}^n) \to C^\infty(\mathbb{R}^n)
:
f \mapsto f\circ \varphi.
\]
Die Umkehrabbildung ist $T_\varphi^{-1}=T_{\varphi^{-1}}$.
Der Operator $P$ heisst invariant, wenn 
\[
T_\varphi^{-1} P T_\varphi = P
\]
gilt.

%
% Die Transformation $T_\varphi$ und das Symbol
%
\subsubsection{Die Transformation $T_\varphi$ und das Symbol}
Bei einer Translation des Raumes $\mathbb{R}^n$ ändert die Differenz
$x-y$ in der Exponentialfunktion der Definition eines
Pseudodifferentialoperators nicht, es kommt also nur auf das Verhalten
des Symbols $a(x,k)$ in Abhängigkeit von $x$ an.
Der Differentialoperator $P$ ist invariant unter Translationen,
wenn das Symbol $a(x,k)$ nicht von $x$ abhängt.

Eine Drehung des Raumes um einen Punkt $x$ kann durch eine Translation
des Punktes $x$ in den Punkt $0$ als Drehung um den Nullpunkt
mit einer Drehmatrix $R$ geschrieben werden.
Das Symbol muss dazu durch $\tilde{a}(y,k) = a(y+x,k)$ ersetzt werden.
Es genügt also, Drehungen mit einer orthogonalen Matrix $R$ um den
Nullpunkt zu betrachten.

Wir suchen also Kriterien dafür, dass der Differentialoperator $P$ unter
einer Drehung um den Nullpunkt invariant bleibt.
Da $P$ ein Differentialoperator ist, ist sein Träger im Nullpunkt
konzentriert, die Werte $a(x,k)$ des Symbols für $x\ne 0$ spielen also
keine Rolle, nur die Abhängigkeit $k\mapsto a(0,k)$ ist relevant.

Die Fourier-Transformierte einer Funktion $f\in C^{\infty}(\mathbb{R}^n)$
ändert sich unter der Drehung um den Nullpunkt gemäss
\[
\widehat{T_Rf}(k)
=
\frac{1}{(\!\sqrt{2\pi})^n}
\int_{\mathbb{R}^n}
e^{-ik\cdot Rx}
f(Rx)\,dx
=
\frac{1}{(\!\sqrt{2\pi})^n}
\int_{\mathbb{R}^n}
e^{-i(R^tk)\cdot x}
f(Rx)\,dx
=
\hat{f}(R^tk)
=
(T_{R^t}f)(k).
\]
Die Drehung mit der Matrix im Ortsraum läuft also auf eine entgegengesetzte
Drehung im Frequenzraum hinaus.
Für den Pseudodifferentialperator $P$ bedeutet dies, dass $P$ genau dann
invariant ist, wenn das Symbol $a(x,k)$ sich nicht ändert, wenn man $k$ durch
$R^tk$ ersetzt.
Die rotationsinvarianten Differentialoperatoren sind also genau jene, 
für die $k\mapsto a(x,k)$ rotationsinvariant ist.

%
% Differentialoperatoren erster Ordnung
%
\subsubsection{Differentialoperatoren erster Ordnung}
Die Abbildung $k\mapsto a(x,k)$ ist ein Polynom in den Variablen
$k_1,\dots,k_n$.
Bei einem Differentialoperator erster Ordnung ist das Symbol daher
eine lineare Funktion
\begin{equation}
a(x,k)
=
a_0(x,k)
+
a_1(x)k_1
+
\dots
+
a_n(x)k_n.
\label{buch:operatoren:casimir:eqn:oplin}
\end{equation}
Die Permutationen der Variablen $k_1,\dots,k_n$ sind orthogonale Abbildungen.
Im Operator \eqref{buch:operatoren:casimir:eqn:oplin} ändert dabei nur
die Reihenfolge der Koeffizienten der linearen Terme, er kann also nur dann
invariant sein, wenn alle $a_1(x),\dots,a_n(x)$ gleich sind.
Die Spiegelung $x_i\mapsto -x_i$ ist aber auch eine orthogonale Abbildung,
der Operator \eqref{buch:operatoren:casimir:eqn:oplin} kann nur invariant
sein, wenn sich bei einem Vorzeichenwechsel von $k_i$ nichts ändert,
d.~h.~wenn alle Koeffizienten $a_1(x)=\dots = a_n(x)=0$ verschwinden.
Es gibt also keinen invarianten Differentialoperator erster Ordnung.

%
% Invariante Differentialoperatoren höhrer Ordnung
%
\subsubsection{Invariante Differentialoperatoren höherer Ordnung}
Die Überlegungen des vorangegangenen Abschnittes zeigen auch,
dass das Symbol eines invarianten Differentialoperators nur gerade
Potenzen der Variablen $k_1,\dots,k_n$ enthalten kann, und
dass alle Koeffizienten $a_{\bm{l}}(x)$, die durch Permutation der
Indizes im Multiindex $\bm{l}$ auseinander hervorgehen, gleich
sein müssen.

Die genannten Bedingungen sind allerdings noch nicht ausreichend.
Für $n=2$ ist das Polynom $k_1^2k_2^2$ vierten Grades zwar invariant
unter der Vertauschung der Indizes $1$ und $2$, aber für eine
beliebige Drehung um den Winkel $\alpha$ werden $k_1$ und $k_2$
zu
$k_1' = k_1\cos\alpha -k_2\sin\alpha$
bzw.~
$k_2' = k_1\sin\alpha +k_2\cos\alpha$.
Eingesetzt in das Polynom entsteht
\begin{align*}
k_1^{\prime 2}
k_2^{\prime 2}
&=
(k_1\cos\alpha -k_2\sin\alpha)^2
(k_1\sin\alpha +k_2\cos\alpha)^2
\\
&=
(k_1^2\cos^2\alpha -2k_1k_2\cos\alpha\sin\alpha +k_2^2\sin^2\alpha)
(k_1^2\sin^2\alpha +2k_1k_2\cos\alpha\sin\alpha +k_2^2\cos^2\alpha)
\\
&=
(k_1^4-4k_1^2k_2^2+k_2^4)\cos^2\alpha\sin^2\alpha
+
k_1^2k_2^2(\cos^4\alpha+\sin^4\alpha)
\\
&\qquad
+
2k_1^3k_2\cos^3\alpha\sin\alpha
-
2k_1^3k_2\cos\alpha\sin^3\alpha
-
2k_1k_2^3\cos^3\alpha\sin\alpha
+
2k_1k_2^3\cos\alpha\sin^3\alpha
\\
&=
(k_1^4-2k_1^2k_2^2+k_2^4)\cos^2\alpha\sin^2\alpha
+
k_1^2k_2^2(\cos^4\alpha-2\cos^2\alpha\sin^2\alpha+\sin^4\alpha)
\\
&\qquad
+
2k_1k_2\cos\alpha\sin\alpha(
k_1^2\cos^2\alpha
-
k_1^2\sin^2\alpha
-
k_2^2\cos^2\alpha
+
k_2^2\sin^2\alpha
)
\\
&=
(k_1^2-k_2^2)^2
\cos^2\alpha\sin^2\alpha
+
k_1^2k_2^2
(\cos^2\alpha-\sin^2\alpha)^2
\\
&\qquad
+
2k_1k_2
\cos\alpha\sin\alpha
(k_1^2-k_2^2)\cos2\alpha
\\
&=
(k_1^2-k_2^2)^2
\frac14\sin^22\alpha
+
k_1^2k_2^2
\cos^22\alpha
\\
&\qquad
+
k_1k_2
\cos2\alpha
(k_1^2-k_2^2)
\sin2\alpha
\\
&=
\bigl(k_1k_2\cos2\alpha + {\textstyle\frac12}(k_1^2-k_2^2)\sin2\alpha\bigr)^2.
\end{align*}
Für $\alpha=0$ stimmen die beiden Seiten überein.
Invarianz bedeutet, dass dieser Ausdruck für alle Paare $(k_1,k_2)$
nicht von $\alpha$ abhängt, das ist aber für $k_1\ne0$ und $k_2=0$ nicht,
der Fall, denn in diesem Fall wird die Gleichung zu
\[
0
=
-
\frac12 k_2^2\sin2\alpha,
\]
was nur für $\alpha=\pi s$, $s\in\mathbb{Z}$ erfüllt ist.

%
% Der Laplace-Operator
%
\subsubsection{Der Laplace-Operator}
Nach den Erkenntnissen des vorangegangenen Abschnitts ist der einzige
unter Drehungen invariante Differentialoperator zweiter Ordnung der 
Operator mit dem Symbol
\[
a(x,k) 
=
a(x)(k_1^2+\dots+k_n^2).
\]
Zurückübersetzt in einen gewöhnlichen Differentialoperator entspricht
dies dem Operator
\[
-a(x)
\biggl(
\frac{\partial^2}{\partial x_1^2}
+
\dots
+
\frac{\partial^2}{\partial x_n^2}
\biggr)
,
\]
also einem Vielfachen des Laplace-Operators
\[
\Delta
=
\frac{\partial^2}{\partial x_1^2}
+
\dots
+
\frac{\partial^2}{\partial x_n^2}.
\]
Das verbreitete Auftreten des Laplace-Operators in Anwendungen ist
also ein Ausdruck der Isotropie des Raumes: in einem Punkt ändern sich
die Naturgesetze bei einer Drehung des Raumes um den Punkt nicht.

%
% Invariante Differentialoperatoren höherer Ordnung
%
\subsubsection{Invariante Differentialoperatoren höhrer Ordnung}
Für das Symbol $k_1^2k_2^2$ wurde bereits gezeigt, dass es nicht das Symbol
eines invarianten Differentialoperators vierter Ordnung sein kann.
Ein Differentialoperator vierter Ordnung auf $C^\infty(\mathbb{R}^2)$
muss also aus weiteren Monomen vierten Grades zusammensetzen.
Die Koeffizienten der Terme $k_1^4$ und $k_2^4$ müssen dabei gleich
sein, das Symbol muss also die Form
\[
a(x,k)
=
ak_1^4 + 2bk_1^2k_2^2 + ak_2^4
\]
haben.
Dies lässt sich aber immer schreiben als
\[
a(x,k)
=
a(k_1^2+k_2^2)^2 + (b-a)k_1^2k_2^2.
\]
Der erste Term ist als Quadrat der Länge invariant unter Drehungen,
vom zweiten Term wissen wir bereits, dass er nicht invariant ist.
Somit ist das einzige möglich invariante Symbol vierten Grades
der Falle $b=a$ und damit  $a(x,k) = (k_1^2+k_2^2)^2$.
Der zugehörige Differentialoperator ist dann 
\[
\Delta \Delta
=
\biggl(
\frac{\partial^2}{\partial x_1^2}
+
\frac{\partial^2}{\partial x_2^2}
\biggr)^2.
\]

Für einen Differentialoperator vierter Ordnung auf $\mathbb{R}^n$ kann
man den Unterraum der Funktionen betrachten, die nur von zwei der
Variablen abhängen.
Auf dem Unterraum der nur von $x_k$ und $x_l$ abhängigen Funktionen
besteht der Operator nur aus den Ableitungen
nach $x_k$ und $x_l$:
\[
\biggl(
\frac{\partial^2}{\partial x_k^2}
+
\frac{\partial^2}{\partial x_l^2}
\biggr)^2.
\]
Daraus leitet man ab, dass der einzige unter Drehungen invariante
Differentialoperator vierter Ordnung ein Vielfaches von
\[
\Delta\Delta 
=
\biggl(
\frac{\partial^2}{\partial x_1^2}
+
\dots
+
\frac{\partial^2}{\partial x_n^2}
\biggr)^2
\]
ist.
Dieser Operator heisst auch der {\em biharmonische Operator}, er
\index{Operator!biharmonisch}%
\index{biharmonischer Operator}%
kommt zum Beispiel in der Plattengleichung vor.

%
% Differentialoperatoren auf einer Lie-Gruppe
%
\subsection{Invariante Differentialoperatoren auf einer Lie-Gruppe}
Der Laplace-Operator hat sich als der Operator herausgestellt, der
der Isotropie des Raumes in jedem Punkt Rechnung trägt.
Der Operator ist insbesondere um die Drehungen um jeden Punkt
invariant.
Die Invarianzeigenschaft ist natürlich eine Eigenschaft der 
vorliegenden Gruppe, die im vorliegenden Fall die
orthogonale Gruppe $\operatorname{O}(n)$ ist.

%
% Differentialoperatoren auf einer Lie-Gruppe
%
\subsubsection{Differentialoperatoren auf einer Lie-Gruppe}
Eine Lie-Gruppe ist auch eine Mannigfaltigkeit, d.~h.~sie sieht lokal
wie ein $\mathbb{R}^n$ aus.
Durch Wahl eines Koordinatensystems kann man auch partielle
Ableitungen von Funktionen auf der Gruppe nach diesen Koordinaten
definieren.
Diese sind jedoch einigermassen willkürlich und tragen der
Gruppenstruktur nicht Rechnung.

Ein besserer Ansatz ist, Kurven auf der Gruppe zu verwenden, die
die Gruppenstruktur bereits berücksichtigen.
Kurven sind Abbildungen von $\mathbb{R}$ in die Gruppe $G$.
Da $\mathbb{R}$ die einfachste Lie-Gruppe ist, könnte man solche
Kurven als Homomorphismen
\[
\gamma
\colon
\mathbb{R} \to  G
\]
definieren.
Sie erfüllen die Homomorphismuseigenschaft
\[
\gamma(t_1+t_2) = \gamma(t_1)\gamma(t_2).
\]
Mit Hilfe von Darstellungen können wir uns eine Lie-Gruppe immer als
eine Gruppe von Matrizen vorstellen.
Eine Kurve $\gamma\colon \mathbb{R}\to G$ ist daher auch eine Kurve in
der offenen Menge $\operatorname{GL}_n(\mathbb{R})$, in der es klar ist,
wie differenziert werden kann:
Die Matrixelemente werden nach dem Parameter $t$ abgeleitet.

Aus der Homomorphismusbedingung
\begin{equation}
\gamma(s+t)=\gamma(s)\gamma(t)
\label{buch:operatoren:casimir:eqn:homomorph}
\end{equation}
erhält man durch Ableiten nach $t$ und der Substitution $t=0$ die 
Differentialgleichung
\[
\dot{\gamma}(s) = \gamma(s) \dot{\gamma}(0),
\]
die als Lösung die Exponentialfunktion
\[
\gamma(t) = \gamma(0) \exp(\dot{\gamma}(0)\cdot t)
\]
hat.
Für $t=0$ ist $\gamma(t)=C\in G$ eine Matrix in der Gruppe.
Alle möglichen Kurven entstehen also durch die Exponentialfunktion.

Leitet man
\eqref{buch:operatoren:casimir:eqn:homomorph}
nach $s$ ab, erhält man als Lösungskurven
\(
t\mapsto \gamma(t) = \exp(\dot{\gamma}(0)) \gamma(0).
\)
Die beiden Kurven stimmen nur dann überein, wenn die beiden Matrizen
$\gamma(0)$ und $\dot{\gamma}(0)$ übereinstimmen.

Die Ableitung einer Funktion $f\colon G\to\mathbb{R}$ in Richtung von
$X=\dot{\gamma(0)}$ im Punkt $e\in G$ ist jetzt definiert als
\[
Xf(e)
=
\frac{d}{dt} f(\exp(tX)) \bigg|_{t=0}.
\]
Die Matrix $X=\dot{\gamma}(0)$ kann als Tangentialvektor der Gruppe
im Punkt $e\in G$ betrachtet werden.
Ein Tangentialvektor im Punkt $e\in G$ entspricht daher einem
Ableitungsoperator im gleichen Punkt.

Ein Differentialoperator entsteht durch Definition eines Tangentialvektors
in jedem Punkt der Gruppe.
Für eine Matrizengruppe bedeutet dies, eine Abbildung $G\to M_n(\mathbb{R})$ 
vorzugeben.
Die Ableitung im Punkt $g\in G$ wird dann bestimmt durch die
Ableitung einer Funktion entlang der Kurve $t\mapsto g\exp(tX(g))$.
Diese wird auch
\[
Xf(g)
=
\frac{d}{dt}f(g\exp(tX(g)))\bigg|_{t=0}
\]
geschrieben.
Der Differentialoperator $X$ ist also ein Vektorfeld von Tangentialvektoren.
Durch wiederholte Anwendung können Operatoren höherer Ordnung konstruiert
werden.

%
% Invariante Operatoren
%
\subsubsection{Invariante Differentialoperatoren}
Wir haben früher untersucht, wie ein Mass auf der Gruppe unter Translation
invariant sein kann und als Antwort das haarsche Mass gefunden.
Ein Mass ist invariant, wenn das Integral einer Funktion auf $G$ nicht
ändert, wenn die Funktion mit $T_g$ translatiert wird.
Ein Differentialoperator wirkt auf die Funktion $f$ im Punkt $g^{-1}\in G$
durch Ableitung entlang der Kurve $t\mapsto g^{-1}\exp(tX(g^{-1}))$.
Auf die verschobene Funktion wirkt er im Punkt $e$ durch Ableitung
der Funktion $T_gf$ entlang der Kurve $t\mapsto \exp(tX(e))$.
Der Differentialoperator ist unter $T_g$ {\em invariant}, wenn die beiden
Ableitungen übereinstimmen.
Diese sind
\[
\frac{d}{dt} f(g^{-1}\exp(tX(g^{-1}))) \bigg|_{t=0}
=
\frac{d}{dt} T_gf(\exp(tX(e)))\bigg|_{t=0}
=
\frac{d}{dt} f(g^{-1}\exp(tX(e)))\bigg|_{t=0}.
\]
Diese können nur dann für alle $g\in G$ gleich sein, wenn
$X(g^{-1}) = X(e)$ gilt.
Die unter $T_g$ invarianten Differentialoperatoren entsprechen also
bijektiv den Tangentialvektoren im neutralen Element.

\begin{definition}
Die linksinvarianten Vektorfelder auf einer Lie-Gruppe $G$ bilden 
den $n$-dimensionalen Vektorraum $LG$.
\end{definition}

Ein rechtsinvarianter Differentialoperator kann analog mit Hilfe
der Rechtstranslation $R_g$ definiert werden, die $(R_gf)(h) = f(hg)$
erfüllt.
Die Ableitung einer Funktion $f$ im Punkt $g\in G$ in Richtung $X(g)$
wird durch die Kurve $t\mapsto g\exp(tX(g))$ gefunden.
Die mit $R_g$ verschobene Funktion $R_gf$ wird von $X$ im Punkt $e$
durch Ableitung entlang der Kurven $t\mapsto \exp(tX(e))$.
Der Operator $X$ heisst {\em rechtsinvariant}, wenn 
\[
\frac{d}{dt} f(g\exp(tX(g))\bigg|_{t=0}
=
\frac{d}{dt} (R_gf)(\exp(tX(e)))\bigg|_{t=0}
=
\frac{d}{dt} f(\exp(tX(0)g))\bigg|_{t=0}
\]
für alle $g\in G$ gilt.
Dies ist nur möglich, wenn die beiden Kurven
$g\exp(tX(g))$
und 
$\exp(tX(e))g$
für $t=0$ den gleichen Tangentialvektor haben, wenn also
\[
\frac{d}{dt}g\exp(tX(g))\bigg|_{t=0}
=
\frac{d}{dt}\exp(tX(e))g\bigg|_{t=0}
\quad\Leftrightarrow\quad
gX(g) = X(e)g
\quad\Leftrightarrow\quad
gX(g)g^{-1} = X(e)
\]
gilt.

Der Unterschied zwischen Rechts- und Linkstranslation wird also gemessen
durch die Grösse $gX(g)g^{-1}-X(e)$.
Ein Vektorfeld ist genau dann invariant, wenn diese Grösse verschwindet.
Für ein bereits linksinvariantes Vektorfeld $X$ wird die Grösse zu
$gXg^{-1}-X$.

In einer Umgebung des neutralen Elementes kann man jedes Gruppenelement
$g$ als Punkt einer Kurve $g=\exp Y$ für ein geeignetes linksinvariantes
Vektorfeld $Y$ schreiben.
Die Bedingung $gXg^{-1}=X$ wird erfüllt, wenn sie für jedes $g(t)=\exp tY$
mit $t<1$ erfüllt wird, wenn also
\begin{equation}
g(t)Xg(t)^{-1}=X
\label{buch:operatoren:casimir:eqn:invarianz}
\end{equation}
ist.
Die Inverse von $g(t)$ kann dabei einfacher als $g^{-1}(t)=\exp(-tY)$
geschreiben werden.

Die Ableitung der Invarianzbedingung
\eqref{buch:operatoren:casimir:eqn:invarianz}
ist $0$ für alle $t$.
Die Ableitung der linken Seite nach $t$ an der Stelle $t=0$ ist
\begin{equation}
\frac{d}{dt} g(t)Xg^{-1}(0)\bigg|_{t=0}
=
\dot{g}(0)Xg^{-1}(0)
+
g(0) X \frac{dg^{-1}}{dt}(0)
=
\frac{d}{dt}e^{tY}\bigg|_{t=0}
X
+
X
\frac{d}{dt}e^{-tY}\bigg|_{t=0}
=
YX-XY.
\label{buch:operatoren:casimir:eqn:innad}
\end{equation}

\begin{definition}
Die Abbildung
\[
\operatorname{ad}_Y\colon LG \to LG:X\mapsto [Y,X] = YX-XY
\]
heisst die {\em adjungierte Abbildung}.
\end{definition}

Die adjungierte Abbildung ist für alle Elemente $Y\in LG$ definiert,
es gibt also auch eine Abbildung
\[
[\;\,,\;]
\colon
LG\times LG
:
(Y,X)
\mapsto
[Y,X] = YX-XY,
\]
die offensichtlich bilinear und antisymmetrisch ist.
Sie macht den Vektorraum $LG$ zu einer sogenannten Lie-Algebra.

\begin{definition}
Ein Vektorraum $V$ mit einem bilinearen und antisymmetrischen
Produkt
\[
[\;\,,\;]
\colon
V\to V
:
(Y,X) \to [Y,X]
\]
heisst eine {\em Lie-Algebra}, wenn die sogenannte
{\em Jacobi-Identität}
\[
[X,[Y,Z]]
+
[Y,[Z,X]]
+
[Z,[X,Y]]
=
0
\]
für alle Vektoren $X,Y,Z\in V$
erfüllt ist.
Das Produkt $[X,Y]$ in der Lie-Algebra heisst auch die
{\em Lie-Klammer} von $X$ und $Y$.
\end{definition}

Eine unmittelbare Folge aus der Jacobi-Identität ergibt sich
aus der Rechnung
\begin{align}
\operatorname{ad}_Z([X,Y])
&=
[Z,[X,Y]]
\\
&=
-[X,[Y,Z]]
-[Y,[Z,X]]
=
[X,[Z,Y]]
+
[[Z,X],Y]
\notag
\intertext{und mit der adjungierten Darstellung geschrieben:}
\operatorname{ad}_Z([X,Y])
&=
[X,\operatorname{ad}_Z(Y)]
+
[\operatorname{ad}_Z(X),Y].
\label{buch:operatoren:casimir:eqn:lieklammerinvariant}
\end{align}
Eine solche Operation heisst auch eine {\em Derivation}.

Für abelsche Gruppen sind Rechts- und Linkstranslation identisch,
die adjungiert Abbildung wird daher für alle Tangentialvektoren $=0$.
Die Lie-Klammer misst also, wie ``nichtkommutativ'' die Gruppe ist.

\begin{beispiel}
Die Gruppe $\operatorname{SO}(2)$ der $2\times 2$-Drehmatrizen
besteht aus Matrizen der Form
\[
\gamma(t)
=
\begin{pmatrix}
\cos t &          -  \sin t \\
\sin t & \phantom{-} \cos t
\end{pmatrix}.
\]
Der Tangentialvektor dieser Kurve bei $t=0$ ist
\[
\dot{\gamma}(0)
=
\begin{pmatrix}
-\sin t & -\cos t \\
 \cos t & -\sin t
\end{pmatrix}
\bigg|_{t=0}
=
\begin{pmatrix}
0&-1\\
1&0
\end{pmatrix}
=J.
\]
Alle Drehmatrizen entstehen als Werte der Exponentialfunktion
\[
\gamma(t)
=
\exp(tJ)
=
I \cos t + J \sin t.
\]
Die Lie-Algebra von $\operatorname{SO}(2)$ ist also eindimensional.
\end{beispiel}

\begin{beispiel}
Die $3\times 3$-Drehmatrizen bilden die Gruppe $\operatorname{SO}(3)$.
Sie enthält die speziellen Drehmatrizen in den Koordinatenebenen
\begin{align*}
D_{x,t}
&=
\begin{pmatrix}
1 & 0      & \phantom{-}0      \\
0 & \cos t &          - \sin t \\
0 & \sin t & \phantom{-}\cos t
\end{pmatrix}
\\
D_{y,t}
&=
\begin{pmatrix}
\phantom{-}\cos t & 0 & \sin t \\
\phantom{-}0      & 1 & 0      \\
         - \sin t & 0 & \cos t
\end{pmatrix}
\\
D_{z,t}
&=
\begin{pmatrix}
\cos t &          - \sin t & 0\\
\sin t & \phantom{-}\cos t & 0\\
0      & \phantom{-}0      & 1
\end{pmatrix}.
\end{align*}
Aus diesen Matrizen lassen sich beliebige Drehungen des Raumes
zusammensetzen, wie man zum Beispiel mit Hilfe der Darstellung durch
Eulerwinkel zeigen kann.
Die Ableitungen davon an der Stelle $t=0$ sind die Matrizen
\[
J_1
=
\dot{D}_{x,0}
=
\begin{pmatrix*}[r]
0&0& 0\\
0&0&-1\\
0&1& 0
\end{pmatrix*}
,\quad
J_2
=
\dot{D}_{y,0}
=
\begin{pmatrix*}[r]
 0&0&1\\
 0&0&0\\
-1&0&0
\end{pmatrix*}
,\quad
J_3
=
\dot{D}_{z,0}
=
\begin{pmatrix*}[r]
0&-1&0\\
1& 0&0\\
0& 0&0
\end{pmatrix*}.
\qedhere
\]
\end{beispiel}

\begin{beispiel}
Das Vektorprodukt auf $\mathbb{R}$ ist bilinear und antisymmetrisch.
Aus der Definition des Vektorproduktes kann man für die Standardbasisvektoren
unmittelbar die Relationen
\[
e_1\times e_2
=
e_3,
\qquad
e_2\times e_3
=
e_1
\qquad\text{und}\qquad
e_3\times e_1
=
e_2
\]
ableiten.
Diese stimmen mit den Kommutatorrelationen der Matrizen $J_k$ der
Lie-Algebra $L\operatorname{SO}(e)$ von $\operatorname{SO}(e)$ überein.
Die lineare Abbildung
\[
\mathbb{R}^3 \to L\operatorname{SO}(3):
\begin{cases}
e_1 \mapsto J_1&\\
e_2 \mapsto J_2&\\
e_3 \mapsto J_3&
\end{cases}
\]
ist bijektiv und
führt das Vektorprodukt in die Lie-Klammer über.
Daraus kann man schliessen, dass das Vektorprodukt ebenfalls für beliebige
Vektoren $\vec{a}$, $\vec{b}$ und $\vec{c}$ die Jacobi-Identität
\[
\vec{a}\times (\vec{b}\times\vec{c})
+
\vec{b}\times (\vec{c}\times\vec{a})
+
\vec{c}\times (\vec{a}\times\vec{b})
=
0
\]
erfüllt.
Der Vektorraum $\mathbb{R}^3$ mit dem Vektorprodukt ist also eine
zu $L\operatorname{SO}(3)$ isomorphe Lie-Algebra.
\end{beispiel}

%
% Das Zentrum einer Lie-Algebra
%
\subsubsection{Das Zentrum einer Lie-Algebra}
Auf einer nichtkommutativen Lie-Algebra $L$ sind die einzigen invarianten
Differentialoperatoren die invarianten Vektorfelder $X$, die mit allen
anderen Vektoren der Lie-Algebra vertauschen, für die also gilt
$[Y,X]=0$ für alle $Y\in L$.

\begin{definition}
Sei $L$ eine Lie-Algebra, dann heisst die Menge
\[
Z(L)
=
\{z\in L\mid [z,x]=0\forall x\in L\}
\]
das {\em Zentrum} von $L$.
\end{definition}

In einer kommutativen Lie-Algebra ist das Zentrum $Z(G)=L$ die ganze
Lie-Algebra, alle Operatoren sind invariant.
Für die Lie-Algebra $L\operatorname{SO}(3)$ wurde gezeigt, dass sie
isomorph ist zur Algebra der dreidimensionalen Vektoren mit dem
Vektorprodukt.
Zu jedem Vektor $\vec{a}\ne 0$ gibt es einen dazu orthogonalen Vektor
$\vec{b}$, das Vektorprodukt $\vec{a}\times\vec{b}$ ist ein Vektor
orthogonal auf beiden Vektoren und ist daher $\ne 0$.
Somit besteht das Zentrum der Lie-Algebra von $\operatorname{SO}(3)$ nur
aus dem Nullvektor.
Insbesondere gibt es keine invarianten Differentialoperatoren erster
Ordnung auf $\operatorname{SO}(3)$.

%
% invariante quadratische Formen
%
\subsubsection{Invariante Bilinearformen}
Eine Lie-Gruppe, deren Lie-Algebra Zentrum $Z(LG)=0$ hat, hat keine
invarianten Differentialoperatoren erster Ordnung.
Ein invarianter Differentialoperator hat also mindestens Ordnung 2.
Es stellt sich somit die Frage, wie man aus Differentialoperatoren
erster Ordnung einen invarianten Differentialoperator zweiter
Ordnung zusammensetzen kann.

Ein Differentialoperator zweiter Ordnung ist eine Linearkombination
von Produkten von jeweils zwei Differentialoperatoren erster Ordnung,
also eine Summe der Form
\[
P
=
\sum_{i,k=1}^n a_{ik} X_i X_k.
\]
Dabei darf man annehmen, dass die $X_i$ Basisvektoren der Lie-Algebra
sind.
Einem Differentialoperator $P$ entspricht also immer eine
Bilinearform.
Ein invarianter Differentialoperator zweiter Ordnung kann folglich
dadurch gefunden werden, dass man eine invariante Bilinearform
konstruiert.

Sei also $\beta(X,Y)$ eine Bilinearform auf der Lie-Algebra $LG$.
Sie ist trivialerweise bereits linksinvariant, da sie aus der
Lie-Algebra konstruiert worden ist.
Es ist also nur noch zu ermitteln, unter welchen Voraussetzungen
sie auch rechtsinvariant ist.
Die Wirkung eines Elementes $g$ von rechts wurde früher
in \eqref{buch:operatoren:casimir:eqn:innad} als
die Konjugation erkannt, Invarianz von $\beta$ bedeutet daher:
\begin{equation}
\beta(X,Y)
=
\beta(gXg^{-1},gYg^{-1}).
\label{buch:operatoren:casimir:eqn:bilinearinvarianz}
\end{equation}
Schreibt man jetzt $g(t)=\exp(tZ)$, dann folgt aus der
Bedingung~\eqref{buch:operatoren:casimir:eqn:bilinearinvarianz},
dass
\[
\beta(X,Y)
=
\beta(g(t)Xg(t)^{-1},g(t)Yg(t)^{-1})
\]
konstant ist.
Die Ableitung muss also verschwinden, Sie kann zunächst mit der
Produktregel bestimmt werden:
\begin{align*}
0
&=
\frac{d}{dt}\beta(g(t)Xg(t)^{-1}, g(t)Yg(t)^{-1})\bigg|_{t=0}
=
\beta\biggl(\frac{d}{dt}g(t)Xg(t)^{-1}\bigg|_{t=0}, Y\biggr)
+
\beta\biggl(X,\frac{d}{dt}g(t)Yg(t)^{-1}\bigg|_{t=0}\biggr).
\intertext{Die inneren Ableitungen wurden früher bereits als die
Lie-Klammern $[X,Z]$ bzw.~$[Y,Z]$ erkannt, sommit folgt als Bedingung
für Invarianz}
0&=\beta([X,Z],Y) + \beta(X,[Y,Z]).
\end{align*}

\begin{satz}
\label{buch:operatoren:casimir:satz:invariantebilinearform}
Eine Bilinearform $\beta(X,Y)$ auf einer Lie-Algebra ist invariant
genau dann, wenn
\[
\beta([Z,X],Y) + \beta(X,[Z,Y])
=
\beta(\operatorname{ad}_Z(X),Y)
+
\beta(X,\operatorname{ad}_Z(Y))
=
0
\]
gilt.
\end{satz}

Die Lie-Klammer $[X,Y]$ ist eine Bilinearform.
In \eqref{buch:operatoren:casimir:eqn:lieklammerinvariant} tritt
die Invarianzbedingung von
Satz~\ref{buch:operatoren:casimir:satz:invariantebilinearform}
auf der rechten Seite aus.
Aus dem Satz folgt daher, dass $[X,Y]$ genau dann eine invariante
Bilinearform ist, wenn $\operatorname{ad}_Z([X,Y])=0$ ist, wenn also
$[X,Y]$ im Zentrum von $LG$ liegt.
Für interessante Lie-Algebren ist dies normalerweise nicht der Fall,
so dass wir auf einem anderen Weg nach invarianten Bilinearformen
suchen müssen, die hoffentlich auf invariante Differentialoperatoren
zweiter Ordnung führen werden.

%
% Casimir-Operator
%
\subsubsection{Casimir-Operator}

\begin{satz}
Ist $\Phi\colon LG\times LG\to\mathbb{R}$ eine symmetrische, invariante
und nichtentartete Bilinearform auf der $n$-dimennsionalen Lie-Algebra
$LG$ von $G$, und $X_i$ eine bezüglich $\Phi$
orthogonale Basis von $LG$ mit der Eigenschaft
\[
\Phi(X_i,X_i) = \varepsilon_i \in \{\pm 1\}\qquad\forall i,
\]
dann ist der Operator
\[
C
=
\sum_{i=1}^n \varepsilon_i X_i^2
\]
ein Differentialoperator, der mit allen anderen Operatoren vertauscht.
\end{satz}

\begin{proof}[Beweis]
Die quadratische Form ist invariant, wenn $\Phi([X,Y],Z)=\Phi(X,[Y,Z])$
gilt.
Wir schreiben die Lie-Klammer zwischen den Basisvektoren als
\[
[X_i,X_j] = \sum_{k=1}^n c_{i\!jk} X_k.
\]
Damit berechnen wir
\begin{align*}
\Phi([X_i,X_j],X_k)
&=
\Phi\biggl(
\sum_{j=1}^n c_{i\!jl}X_l, X_k
\biggr)
=
c_{i\!jk}
\Phi(X_k,X_k)
=
\varepsilon_k c_{i\!jk}
\\
\Phi(X_i,[X_j,X_k])
&=
\Phi\biggl(X_i,
\sum_{l=1}^n c_{jkl}X_l
\biggr)
=
c_{jkl}\Phi(X_i,X_i)
=
\varepsilon_i c_{jki}.
\end{align*}
Es folgt aus der Invarianzbedingung, dass
\begin{equation}
\varepsilon_k c_{i\!jk}
=
\varepsilon_i c_{jki}
\quad\Rightarrow\quad
\varepsilon_i c_{i\!jk}
=
\varepsilon_k c_{jki}
=
-\varepsilon_k c_{k\!ji}.
\label{buch:operatoren:casimir:eqn:invc}
\end{equation}
Damit kann man jetzt die Vertauschung eines Operators mit dem
Operator $C$ berechnen:
\begin{align}
CX_j-X_jC
&=
\sum_{i=1}^n \varepsilon_i ( X_i^2X_j - X_jX_i^2)
\notag
\\
&=
\sum_{i=1}^n \varepsilon_i ( X_i^2X_j - X_iX_jX_i + X_iX_jX_i - X_jX_i^2)
\notag
\\
&=
\sum_{i=1}^n \varepsilon_i (X_i[X_i,X_j] + [X_i,X_j]X_i)
\notag
\\
&=
\sum_{i,k=1}^n \varepsilon_i ( c_{ilk} X_i X_k + c_{ilk} X_k X_i).
\notag
\intertext{Vertauschung der Summationsindizes $i$ und $k$ in der zweiten
Summe ergibt}
&=
\sum_{i,k=1}^n \varepsilon_i c_{i\!jk} X_i X_k
+
\sum_{i,k=1}^n \varepsilon_k c_{k\!ji} X_i X_k)
\notag
\\
&=
\sum_{i,k=1}^n (\varepsilon_i c_{i\!jk}
+
\varepsilon_k c_{k\!ji}) X_i X_k
\label{buch:operatoren:casimir:eqn:summe}
\intertext{Setzt man \eqref{buch:operatoren:casimir:eqn:invc}
in \eqref{buch:operatoren:casimir:eqn:summe} ein, erhält man}
&=
\sum_{i,k=1}^n
(
\varepsilon_i c_{i\!jk}
+
\varepsilon_i c_{jki}
)
X_i X_k
=
\sum_{i,k=1}^n
(
\varepsilon_i c_{i\!jk}
-
\varepsilon_i c_{i\!jk}
)
X_i X_k
=
0.
\end{align}
Somit vertauscht $C$ mit jedem Vektor $X_j$.

Die Definition des Casimir-Operators $C$ hängt von der Wahl der Basis
$X_i$ ab.
Sei $E$ die Diagonalmatrix
$E=\operatorname{diag}(\varepsilon_1,\dots,\varepsilon_n)$.
Koordinatenwechsel zu einer alternativen Basis $\tilde{X}_i$ mit den gleichen
Skalarprodukten erfolgt mit einer Matrix $B$, die $BEB^{t}=E$ erfüllen muss.
Mit dieser Matrix ändert aber auch der Casimir-Operator nicht.
\end{proof}

Der Satz beschreibt eine Konstruktion für einen Differentialoperator,
der mit allen anderen Operatoren vertauscht.
Für die kommutative Lie-Gruppe $G=\mathbb{R}^n$ besagt sie, dass man
dazu zunächst eine nichtentartete, symmetrische Bilinearform suchen muss.
In $\mathbb{R}^n$ erfüllt das Standardskalarprodukt diese Bedingung.
Da alle Lie-Klammern verschwinden, ist es automatisch auch invariant.
Dann muss man eine orthonormierte Basis suchen, die Standardbasis
ist dafür geeignet, sie erfüllen $e_i\cdot e_i=\varepsilon_i=1$.
Die zugehörigen Ableitungsoperatoren sind
\[
e_1 \mapsto X_1 = \frac{\partial}{\partial x_1},
\qquad
e_2 \mapsto X_2 = \frac{\partial}{\partial x_2},
\qquad
e_3 \mapsto X_3 = \frac{\partial}{\partial x_3}.
\]
Dann ist der Casimir-Operator
\[
C=
\sum_{i=1}^3 \varepsilon_i X_i^2
=
\sum_{i=1}^3 \frac{\partial^2}{\partial x_i^2}
=
\Delta.
\]
Der zum Standardskalarprodukt gehörige Casimir-Operator ist also
der Laplace-Operator.

Man kann aber auch auf $\mathbb{R}^4$ den Operator konstruieren, der
zu dem entarteten Minkovski-Skalarprodukt
\[
\Phi(x,y)
=
x_0y_0
-
x_1y_1
-
x_2y_2
-
x_3y_3
\]
gehört, die in der speziellen Relativitätstheorie von zentraler Bedeutung
ist.
Der daraus abgeleitete Casimir-Operator ist
\[
\frac{\partial^2}{\partial x_0^2}
-
\frac{\partial^2}{\partial x_1^2}
-
\frac{\partial^2}{\partial x_2^2}
-
\frac{\partial^2}{\partial x_3^2}
=
-\square
\]
der d'Alembert-Operator, der die Wellenausbreitung beschreibt.

Eine lineare Abbildung, die die invariante Bilinear-Form $\Phi$ unverändert
lässt, vertauscht auch mit dem Casimir-Operator.
Da Drehungen das Standardskalarprodukt invariant lassen, vertauscht
der Laplace-Operator mit den Drehungen.
Ebenso lassen die Lorentz-Transformationen das Minkowski-Skalarprodukt
invariant.
Lorentz-Transformationen vertauschen daher auch mit dem d'Alembert-Operator.

